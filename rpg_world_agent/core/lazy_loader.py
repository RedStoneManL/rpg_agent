"""
Lazy Loader - æ‡’åŠ è½½ä¼˜åŒ–ç³»ç»Ÿ

è¿™ä¸ªç³»ç»Ÿå‡å°‘ä¸å¿…è¦çš„ LLM è°ƒç”¨ï¼Œé€šè¿‡ï¼š
1. ç¼“å­˜å·²ç”Ÿæˆçš„å†…å®¹
2. æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨ LLM
3. ç›¸ä¼¼å†…å®¹å¤ç”¨
4. API è°ƒç”¨é¢‘ç‡æ§åˆ¶

æ ¸å¿ƒåŠŸèƒ½ï¼š
- should_generate_content(): åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ–°å†…å®¹
- get_cached_or_generate(): è·å–ç¼“å­˜æˆ–ç”Ÿæˆæ–°å†…å®¹
- find_similar_content(): æŸ¥æ‰¾ç›¸ä¼¼å†…å®¹
"""

import hashlib
import json
import time
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Set, Tuple
from enum import Enum

from rpg_world_agent.core.event_system import EventSystem
from rpg_world_agent.core.world_state import WorldStateManager

if TYPE_CHECKING:
    from rpg_world_agent.core.runtime import RuntimeEngine


class ContentType(Enum):
    """å†…å®¹ç±»å‹"""
    LOCATION = "location"
    NPC = "npc"
    ITEM = "item"
    QUEST = "quest"
    DIALOGUE = "dialogue"
    NARRATIVE = "narrative"
    DESCRIPTION = "description"
    CUSTOM = "custom"


class GenerationReason(Enum):
    """ç”ŸæˆåŸå› """
    CACHE_MISS = "cache_miss"           # ç¼“å­˜æœªå‘½ä¸­
    STALE_CACHE = "stale_cache"         # ç¼“å­˜è¿‡æœŸ
    FORCE_REFRESH = "force_refresh"     # å¼ºåˆ¶åˆ·æ–°
    CONTEXT_CHANGE = "context_change"   # ä¸Šä¸‹æ–‡å˜åŒ–
    NEW_REQUEST = "new_request"         # æ–°è¯·æ±‚
    NO_SIMILAR = "no_similar"           # æ— ç›¸ä¼¼å†…å®¹


@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    content_type: ContentType
    content: Any
    context_hash: str                  # ç”Ÿæˆæ—¶çš„ä¸Šä¸‹æ–‡å“ˆå¸Œ
    created_at: float
    last_accessed: float
    access_count: int = 0
    ttl_seconds: int = 3600            # é»˜è®¤ 1 å°æ—¶
    tags: Set[str] = field(default_factory=set)

    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        return time.time() - self.created_at > self.ttl_seconds

    def is_context_valid(self, current_context_hash: str) -> bool:
        """æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦ä»ç„¶æœ‰æ•ˆ"""
        return self.context_hash == current_context_hash


@dataclass
class LoadContext:
    """åŠ è½½ä¸Šä¸‹æ–‡"""
    player_id: str
    location: str
    world_state: WorldStateManager
    event_system: EventSystem
    extra: Dict[str, Any] = field(default_factory=dict)

    def compute_hash(self) -> str:
        """è®¡ç®—ä¸Šä¸‹æ–‡å“ˆå¸Œ"""
        data = {
            "player_id": self.player_id,
            "location": self.location,
            "crisis_level": self.world_state.crisis_level.value,
            "time": self.world_state.world_time.total_minutes // 60,  # æŒ‰å°æ—¶èšåˆ
            "flags": sorted(self.world_state.global_flags.keys())
        }
        json_str = json.dumps(data, sort_keys=True)
        return hashlib.md5(json_str.encode()).hexdigest()


@dataclass
class LazyLoadingConfig:
    """æ‡’åŠ è½½é…ç½®"""
    # ç¼“å­˜è®¾ç½®
    cache_ttl_default: int = 3600              # é»˜è®¤ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰
    cache_ttl_location: int = 7200             # åœ°ç‚¹ç¼“å­˜æ—¶é—´
    cache_ttl_npc: int = 1800                  # NPC ç¼“å­˜æ—¶é—´
    cache_ttl_narrative: int = 300             # å™äº‹ç¼“å­˜æ—¶é—´ï¼ˆè¾ƒçŸ­ï¼‰
    max_cache_size: int = 1000                 # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°

    # ç›¸ä¼¼åº¦é˜ˆå€¼
    similarity_threshold: float = 0.8          # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰

    # API è°ƒç”¨æ§åˆ¶
    max_calls_per_minute: int = 20             # æ¯åˆ†é’Ÿæœ€å¤§è°ƒç”¨æ¬¡æ•°
    min_interval_ms: int = 100                 # æœ€å°è°ƒç”¨é—´éš”ï¼ˆæ¯«ç§’ï¼‰

    # æ‡’åŠ è½½ç­–ç•¥
    reuse_similar_content: bool = True         # æ˜¯å¦å¤ç”¨ç›¸ä¼¼å†…å®¹
    context_aware_caching: bool = True         # æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¼“å­˜
    smart_expiration: bool = True              # æ˜¯å¦æ™ºèƒ½è¿‡æœŸ


class ContentCache:
    """
    å†…å®¹ç¼“å­˜

    å­˜å‚¨ç”Ÿæˆçš„å„ç§å†…å®¹ï¼Œæ”¯æŒï¼š
    - æŒ‰ç±»å‹å­˜å‚¨
    - TTL è¿‡æœŸ
    - ä¸Šä¸‹æ–‡éªŒè¯
    - LRU æ·˜æ±°
    """

    def __init__(self, config: Optional[LazyLoadingConfig] = None):
        self.config = config or LazyLoadingConfig()
        self._cache: Dict[str, CacheEntry] = {}
        self._type_index: Dict[ContentType, Set[str]] = {t: set() for t in ContentType}

    def get(self, key: str) -> Optional[CacheEntry]:
        """è·å–ç¼“å­˜æ¡ç›®"""
        entry = self._cache.get(key)
        if entry:
            entry.last_accessed = time.time()
            entry.access_count += 1
        return entry

    def set(
        self,
        key: str,
        content: Any,
        content_type: ContentType,
        context_hash: str,
        ttl_seconds: Optional[int] = None,
        tags: Optional[Set[str]] = None
    ) -> None:
        """è®¾ç½®ç¼“å­˜æ¡ç›®"""
        # æ£€æŸ¥å®¹é‡ï¼Œå¿…è¦æ—¶æ·˜æ±°
        if len(self._cache) >= self.config.max_cache_size:
            self._evict_lru()

        ttl = ttl_seconds or self._get_default_ttl(content_type)

        entry = CacheEntry(
            key=key,
            content_type=content_type,
            content=content,
            context_hash=context_hash,
            created_at=time.time(),
            last_accessed=time.time(),
            ttl_seconds=ttl,
            tags=tags or set()
        )

        # åˆ é™¤æ—§æ¡ç›®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if key in self._cache:
            old_entry = self._cache[key]
            self._type_index[old_entry.content_type].discard(key)

        self._cache[key] = entry
        self._type_index[content_type].add(key)

    def delete(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜æ¡ç›®"""
        if key in self._cache:
            entry = self._cache.pop(key)
            self._type_index[entry.content_type].discard(key)
            return True
        return False

    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        self._cache.clear()
        for type_set in self._type_index.values():
            type_set.clear()

    def get_by_type(self, content_type: ContentType) -> List[CacheEntry]:
        """æŒ‰ç±»å‹è·å–ç¼“å­˜æ¡ç›®"""
        keys = self._type_index.get(content_type, set())
        entries = []
        for key in list(keys):  # å¤åˆ¶ä»¥é˜²è¿­ä»£æ—¶ä¿®æ”¹
            entry = self._cache.get(key)
            if entry and not entry.is_expired():
                entries.append(entry)
        return entries

    def cleanup_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸæ¡ç›®"""
        expired_keys = [
            key for key, entry in self._cache.items()
            if entry.is_expired()
        ]
        for key in expired_keys:
            self.delete(key)
        return len(expired_keys)

    def _evict_lru(self) -> None:
        """æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„æ¡ç›®"""
        if not self._cache:
            return

        # æ‰¾åˆ°æœ€ä¹…æœªä½¿ç”¨çš„æ¡ç›®
        lru_key = min(
            self._cache.keys(),
            key=lambda k: (self._cache[k].access_count, self._cache[k].last_accessed)
        )
        self.delete(lru_key)

    def _get_default_ttl(self, content_type: ContentType) -> int:
        """è·å–å†…å®¹ç±»å‹çš„é»˜è®¤ TTL"""
        ttl_map = {
            ContentType.LOCATION: self.config.cache_ttl_location,
            ContentType.NPC: self.config.cache_ttl_npc,
            ContentType.NARRATIVE: self.config.cache_ttl_narrative,
        }
        return ttl_map.get(content_type, self.config.cache_ttl_default)


class SimilarityMatcher:
    """
    ç›¸ä¼¼åº¦åŒ¹é…å™¨

    ç”¨äºæŸ¥æ‰¾ç›¸ä¼¼çš„å†…å®¹ï¼Œé¿å…é‡å¤ç”Ÿæˆ
    """

    def __init__(self, threshold: float = 0.8):
        self.threshold = threshold

    def find_similar(
        self,
        query: str,
        candidates: List[CacheEntry],
        top_k: int = 3
    ) -> List[Tuple[CacheEntry, float]]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼å†…å®¹

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            candidates: å€™é€‰ç¼“å­˜æ¡ç›®
            top_k: è¿”å›çš„æœ€å¤§æ•°é‡

        Returns:
            List[Tuple[CacheEntry, float]]: (æ¡ç›®, ç›¸ä¼¼åº¦) åˆ—è¡¨
        """
        results: List[Tuple[CacheEntry, float]] = []

        for entry in candidates:
            if isinstance(entry.content, str):
                similarity = self._compute_similarity(query, entry.content)
            elif isinstance(entry.content, dict):
                # å¯¹å­—å…¸å†…å®¹ï¼Œè®¡ç®—æè¿°å­—æ®µçš„ç›¸ä¼¼åº¦
                desc = entry.content.get("description", "")
                name = entry.content.get("name", "")
                combined = f"{name} {desc}"
                similarity = self._compute_similarity(query, combined)
            else:
                continue

            if similarity >= self.threshold:
                results.append((entry, similarity))

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]

    def _compute_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦

        ä½¿ç”¨ç®€åŒ–çš„ Jaccard ç›¸ä¼¼åº¦ï¼ˆåŸºäºè¯é›†åˆï¼‰
        """
        # åˆ†è¯ï¼ˆç®€åŒ–å®ç°ï¼‰
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if not words1 or not words2:
            return 0.0

        # Jaccard ç›¸ä¼¼åº¦
        intersection = len(words1 & words2)
        union = len(words1 | words2)

        return intersection / union if union > 0 else 0.0


class RateLimiter:
    """
    API è°ƒç”¨é¢‘ç‡é™åˆ¶å™¨

    æ§åˆ¶ LLM è°ƒç”¨é¢‘ç‡
    """

    def __init__(self, max_calls_per_minute: int = 20, min_interval_ms: int = 100):
        self.max_calls_per_minute = max_calls_per_minute
        self.min_interval_ms = min_interval_ms
        self._call_times: List[float] = []

    def can_call(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥è°ƒç”¨"""
        now = time.time()

        # æ¸…ç† 1 åˆ†é’Ÿå‰çš„è®°å½•
        cutoff = now - 60
        self._call_times = [t for t in self._call_times if t > cutoff]

        # æ£€æŸ¥è°ƒç”¨æ¬¡æ•°
        if len(self._call_times) >= self.max_calls_per_minute:
            return False

        # æ£€æŸ¥æœ€å°é—´éš”
        if self._call_times:
            last_call = self._call_times[-1]
            if (now - last_call) * 1000 < self.min_interval_ms:
                return False

        return True

    def record_call(self) -> None:
        """è®°å½•ä¸€æ¬¡è°ƒç”¨"""
        self._call_times.append(time.time())

    def wait_time(self) -> float:
        """è·å–éœ€è¦ç­‰å¾…çš„ç§’æ•°"""
        if self.can_call():
            return 0.0

        now = time.time()

        # è®¡ç®—åˆ°ä¸‹ä¸€æ¬¡å¯ç”¨çš„æ—¶é—´
        if len(self._call_times) >= self.max_calls_per_minute:
            oldest = self._call_times[0]
            return max(0, 60 - (now - oldest))

        if self._call_times:
            last_call = self._call_times[-1]
            wait = (self.min_interval_ms / 1000) - (now - last_call)
            return max(0, wait)

        return 0.0


class LazyLoadingStrategy:
    """
    æ‡’åŠ è½½ç­–ç•¥

    å†³å®šä½•æ—¶ç”Ÿæˆæ–°å†…å®¹ï¼Œä½•æ—¶å¤ç”¨ç¼“å­˜
    """

    def __init__(
        self,
        config: Optional[LazyLoadingConfig] = None,
        cache: Optional[ContentCache] = None
    ):
        self.config = config or LazyLoadingConfig()
        self.cache = cache or ContentCache(self.config)
        self.similarity_matcher = SimilarityMatcher(self.config.similarity_threshold)
        self.rate_limiter = RateLimiter(
            self.config.max_calls_per_minute,
            self.config.min_interval_ms
        )

        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            "cache_hits": 0,
            "cache_misses": 0,
            "similar_reused": 0,
            "calls_blocked": 0,
            "total_calls": 0
        }

    def should_generate_content(
        self,
        key: str,
        context: LoadContext,
        content_type: ContentType,
        force: bool = False
    ) -> Tuple[bool, GenerationReason]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆæ–°å†…å®¹

        Args:
            key: å†…å®¹é”®
            context: åŠ è½½ä¸Šä¸‹æ–‡
            content_type: å†…å®¹ç±»å‹
            force: æ˜¯å¦å¼ºåˆ¶ç”Ÿæˆ

        Returns:
            Tuple[bool, GenerationReason]: (æ˜¯å¦ç”Ÿæˆ, åŸå› )
        """
        self._stats["total_calls"] += 1

        # å¼ºåˆ¶ç”Ÿæˆ
        if force:
            return True, GenerationReason.FORCE_REFRESH

        # æ£€æŸ¥ç¼“å­˜
        cached = self.cache.get(key)

        # ç¼“å­˜æœªå‘½ä¸­
        if not cached:
            self._stats["cache_misses"] += 1
            return True, GenerationReason.CACHE_MISS

        # ç¼“å­˜è¿‡æœŸ
        if cached.is_expired():
            self._stats["cache_misses"] += 1
            return True, GenerationReason.STALE_CACHE

        # ä¸Šä¸‹æ–‡å˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼‰
        if self.config.context_aware_caching:
            current_hash = context.compute_hash()
            if not cached.is_context_valid(current_hash):
                self._stats["cache_misses"] += 1
                return True, GenerationReason.CONTEXT_CHANGE

        # ç¼“å­˜å‘½ä¸­
        self._stats["cache_hits"] += 1
        return False, GenerationReason.CACHE_MISS

    def get_cached_or_generate(
        self,
        key: str,
        context: LoadContext,
        content_type: ContentType,
        generator: Callable[[], Any],
        force: bool = False
    ) -> Tuple[Any, bool]:
        """
        è·å–ç¼“å­˜æˆ–ç”Ÿæˆæ–°å†…å®¹

        Args:
            key: å†…å®¹é”®
            context: åŠ è½½ä¸Šä¸‹æ–‡
            content_type: å†…å®¹ç±»å‹
            generator: å†…å®¹ç”Ÿæˆå‡½æ•°
            force: æ˜¯å¦å¼ºåˆ¶ç”Ÿæˆ

        Returns:
            Tuple[Any, bool]: (å†…å®¹, æ˜¯å¦æ–°ç”Ÿæˆ)
        """
        # é¦–å…ˆæ£€æŸ¥ç›¸ä¼¼å†…å®¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config.reuse_similar_content and not force:
            # è¿™é‡Œå¯ä»¥ä¼ å…¥æŸ¥è¯¢è¯ï¼Œä½†ç®€åŒ–å®ç°ä¸­è·³è¿‡
            pass

        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆ
        should_generate, reason = self.should_generate_content(
            key, context, content_type, force
        )

        if should_generate:
            # æ£€æŸ¥é¢‘ç‡é™åˆ¶
            if not self.rate_limiter.can_call():
                self._stats["calls_blocked"] += 1
                # è¿”å›ç¼“å­˜çš„æ—§å†…å®¹ï¼ˆå³ä½¿è¿‡æœŸï¼‰
                cached = self.cache.get(key)
                if cached:
                    return cached.content, False
                # æ²¡æœ‰ç¼“å­˜ï¼Œå¿…é¡»ç­‰å¾…
                return None, False

            # ç”Ÿæˆæ–°å†…å®¹
            content = generator()
            self.rate_limiter.record_call()

            # å­˜å…¥ç¼“å­˜
            context_hash = context.compute_hash() if self.config.context_aware_caching else ""
            self.cache.set(
                key=key,
                content=content,
                content_type=content_type,
                context_hash=context_hash
            )

            return content, True

        # è¿”å›ç¼“å­˜
        cached = self.cache.get(key)
        return cached.content if cached else None, False

    def find_similar_content(
        self,
        query: str,
        content_type: ContentType,
        threshold: Optional[float] = None
    ) -> Optional[Tuple[Any, float]]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼å†…å®¹

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            content_type: å†…å®¹ç±»å‹
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            Optional[Tuple[Any, float]]: (å†…å®¹, ç›¸ä¼¼åº¦) æˆ– None
        """
        if not self.config.reuse_similar_content:
            return None

        old_threshold = self.similarity_matcher.threshold
        if threshold is not None:
            self.similarity_matcher.threshold = threshold

        candidates = self.cache.get_by_type(content_type)
        results = self.similarity_matcher.find_similar(query, candidates, top_k=1)

        self.similarity_matcher.threshold = old_threshold

        if results:
            entry, similarity = results[0]
            self._stats["similar_reused"] += 1
            return entry.content, similarity

        return None

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self._stats["cache_hits"] + self._stats["cache_misses"]
        hit_rate = self._stats["cache_hits"] / total if total > 0 else 0

        return {
            **self._stats,
            "cache_hit_rate": hit_rate,
            "cache_size": len(self.cache._cache)
        }

    def clear_cache(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()

    def cleanup(self) -> int:
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        return self.cache.cleanup_expired()


# =============================================================================
# ğŸ­ ä¾¿æ·å‡½æ•°
# =============================================================================

def create_lazy_loader(
    max_cache_size: int = 1000,
    similarity_threshold: float = 0.8,
    max_calls_per_minute: int = 20
) -> LazyLoadingStrategy:
    """
    åˆ›å»ºæ‡’åŠ è½½ç­–ç•¥å®ä¾‹

    Args:
        max_cache_size: æœ€å¤§ç¼“å­˜å¤§å°
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        max_calls_per_minute: æ¯åˆ†é’Ÿæœ€å¤§è°ƒç”¨æ¬¡æ•°

    Returns:
        LazyLoadingStrategy: æ‡’åŠ è½½ç­–ç•¥å®ä¾‹
    """
    config = LazyLoadingConfig(
        max_cache_size=max_cache_size,
        similarity_threshold=similarity_threshold,
        max_calls_per_minute=max_calls_per_minute
    )
    return LazyLoadingStrategy(config=config)
